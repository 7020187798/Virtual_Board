# -*- coding: utf-8 -*-
"""Untitled8.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11IwNLJo6Qyv6tHSN7PQaexirfe3nK29k
"""

# Import necessary libraries
import cv2
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import load_model



# Import necessary libraries
import tensorflow as tf
from tensorflow.keras.datasets import mnist
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout

# Load the MNIST dataset
(x_train, y_train), (x_test, y_test) = mnist.load_data()

# Normalize the pixel values
x_train = x_train / 255.0
x_test = x_test / 255.0

# Reshape the input data to 4D tensors
x_train = x_train.reshape(-1, 28, 28, 1)
x_test = x_test.reshape(-1, 28, 28, 1)

# Convert the output data to one-hot encoded vectors
y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)
y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)

# Define the CNN model
model = Sequential()
model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Flatten())
model.add(Dense(128, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(10, activation='softmax'))

# Compile the model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Train the model
model.fit(x_train, y_train, epochs=1, batch_size=64, validation_data=(x_test, y_test))

# Save the trained model
model.save('model.h5')

# Load the pre-trained model
model = load_model('model.h5')

# Load the pre-trained model
model = load_model('model.h5')

# Evaluate the model on the test data
loss, accuracy = model.evaluate(x_test, y_test)

# Print the accuracy
print('Accuracy:', accuracy)

# Define the canvas
canvas = np.zeros((480, 640, 3), dtype=np.uint8)

# Set up the video capture
cap = cv2.VideoCapture(0)

# Define the lower and upper bounds of the color to track (in HSV format)
lower_bound = np.array([0, 120, 70])
upper_bound = np.array([10, 255, 255])

# Define the thickness of the brush strokes
brush_thickness = 15

# Start the video capture loop
while True:
    # Read the frame from the video capture
    ret, frame = cap.read()
    
    # Flip the frame horizontally
    frame = cv2.flip(frame, 1)
    
  # Convert the frame from BGR to HSV format
    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
    
    # Create a mask for the color to track
    mask = cv2.inRange(hsv, lower_bound, upper_bound)
    
    # Find the contours in the mask
    contours, hierarchy = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    # Check if any contours are detected
    if contours:
        # Find the largest contour
        max_contour = max(contours, key=cv2.contourArea)
        
        # Get the bounding rectangle of the contour
        x, y, w, h = cv2.boundingRect(max_contour)
        
        # Extract the region of interest from the frame
        roi = frame[y:y+h, x:x+w]
        
        # Resize the ROI to match the input size of the model
        roi = cv2.resize(roi, (28, 28))
        
        # Convert the ROI to grayscale
        roi_gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
        
        # Threshold the ROI
        _, thresh = cv2.threshold(roi_gray, 120, 255, cv2.THRESH_BINARY)
        
        # Flatten the ROI
        flattened = thresh.flatten() / 255.0
        
        # Make a prediction using the model
        prediction = model.predict(np.array([flattened]))
        
        # Get the class with the highest probability
        class_id = np.argmax(prediction)
        
        # Draw the predicted class label on the canvas
        cv2.putText(canvas, str(class_id), (x, y), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), thickness=brush_thickness)
    
    # Display the canvas and the video feed
    cv2.imshow('Air Canvas', canvas)
    cv2.imshow('Video Feed', frame)
    
    # Wait for a key press
    key = cv2.waitKey(1)
    
    # Clear the canvas if the 'c' key is pressed
    if key == ord('c'):
        canvas = np.zeros((480, 640, 3), dtype=np.uint8)
    
    # Quit the program if the 'q' key is pressed
    if key == ord('q'):
        break

# Release the video capture and close all windows
cap.release()
cv2.destroyAllWindows()